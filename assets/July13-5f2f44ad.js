import{_ as g,a as $,b as f,c as b,d as v,e as y}from"./val-loss-c37487be.js";import{r as a,o as h,c as x,w as o,a as s,b as l,d as e,u as t,g as w,l as C,e as V}from"./index-3db09ab9.js";import{_ as M}from"./Week1-602f34fa.js";import{_ as L}from"./Week2-ef1d4b1c.js";import{_ as S}from"./Week3-83dd26ce.js";const I="/Presentation/assets/model-aaa94bef.png",J="/Presentation/assets/demo-2928a38f.png",N=s("h2",null,"Recap of 4th Week",-1),P={class:"grid grid-cols-2"},k=s("li",null,[l(" Our model architecture: "),s("ul",null,[s("li",null,"Encoder: DenseNet & Pyramid Pooling Module"),s("li",null,"Decoder: Transformer decoder")])],-1),E=s("li",null,[l(" Validation accuracy is increased to "),s("span",{class:"red-bold"},"0.61"),l(". ")],-1),R={__name:"Week4",setup(m){return(_,n)=>{const r=a("Image"),d=a("VSection");return h(),x(d,null,{default:o(()=>[N,s("div",P,[s("ul",null,[k,E,s("li",null,[l(" Prototype improvement: "),e(r,{src:t(J),class:"w-full"},null,8,["src"])])]),e(r,{src:t(I),class:"h-1/2"},null,8,["src"])])]),_:1})}}},T="/Presentation/assets/phase3-1a1ac70a.jpg",B={class:"w-screen h-screen"},W={class:"reveal"},D={class:"slides"},O=s("h2",null,"Object Counting",-1),j=s("ul",null,[s("li",null,[l(" Regression-based methods: To learn counting by regressing a "),s("span",{class:"red-bold"},"density map"),l(", and the predicted count equals the integration of the density map. ")]),s("li",null," Multi-scale counting model(MSCM) is designed based on regression-based method, used to predict the number of each symbol class. ")],-1),z=s("span",{class:"text-xl italic"}," Li, B., Yuan, Y., Liang, D., Liu, X., Ji, Z., Bai, J., ... & Bai, X. (2022, October). When counting meets HMER: counting-aware network for handwritten mathematical expression recognition. In European Conference on Computer Vision (pp. 197-214). Cham: Springer Nature Switzerland. ",-1),A=s("h2",null,"Multi-scale Counting Module(MSCM)",-1),H=s("ul",null,[s("li",null," Two parallel multi-scale branches ($3 \\times 3$, $5 \\times 5$) are used to generate counting maps. Channel attention is adopted to enhance the feature extraction. "),s("li",null," In counting map, each map $\\mathbf{M_i}$ is actually a pseudo density map, where $\\mathbf{M_i} \\in \\mathbb{R}^{H \\times W}$. We can obtain counting vector $V$ by sum-pooling the counting map, where $V \\in \\mathbb{R}^{1\\times C}$, $C$ is the vocabulary size. "),s("li",null," Each element in $V$ is the predicted count of the i-th class symbol. ")],-1),F=s("h2",null,"Loss Function",-1),X=s("ul",null,[s("li",null," The updated loss function consists of two parts: $$ L=L_{cls}+L_{counting} $$ where $L=L_{cls}$ is a common-used cross entropy classification loss of the predicted probability with respect to its ground-truth. "),s("li",null," Denoting the counting ground truth of each symbol class as $\\hat{V}$: $$ L_{couting} = \\text{smooth}_{L1}(V, \\hat{V}) $$ "),s("li",null," For batch size $N$, Smooth L1 loss is defined: $$ \\ell(x, y) = L = \\{l_1, ..., l_N\\}^T $$ $$ l_n = \\begin{cases} 0.5 (x_n - y_n)^2, & \\text{if } |x_n - y_n| \\le 1.0 \\\\ |x_n - y_n| - 0.5, & \\text{otherwise } \\end{cases} $$ ")],-1),Y=s("h2",null,"Experiment",-1),q={class:"grid grid-cols-3"},Z=["src"],G=["src"],K=["src"],Q={class:"grid grid-cols-5"},U={class:"col-span-3"},ss=s("span",{class:"red-bold"},"0.597",-1),es=["src"],ts=s("div",{class:"col-span-2"},[s("p",null,"Problems:"),s("ul",null,[s("li",null,"A sharp increse in validation loss."),s("li",null," Validation accuracy is slightly less than experiments done in the last week (0.60). ")]),s("p",null," Reason: We only back-propagate counting loss from the encoder without putting the counting vector into the decoder. ")],-1),ls=s("h2",null,"Next Schedule",-1),ns=s("ul",null,[s("li",null,"Finalize our model and deploy it."),s("li",null,"Write final report."),s("li",null,"Prepare final presentation.")],-1),us={__name:"July13",setup(m){const _=Object.values(Object.assign({"../assets/images/July13/CAN.png":g,"../assets/images/July13/MSCM.png":$,"../assets/images/July13/epoch.svg":f,"../assets/images/July13/train-loss.svg":b,"../assets/images/July13/val-acc.svg":v,"../assets/images/July13/val-loss.svg":y})),n=w(_);return C(),(r,d)=>{const p=a("Cover"),c=a("HSection"),u=a("Image"),i=a("VSection");return h(),V("div",B,[s("div",W,[s("div",D,[e(p,{date:"July 13"}),s("section",null,[e(c,{text:"I. Recap"}),e(t(M)),e(t(L)),e(t(S)),e(t(R))]),s("section",null,[e(c,{text:"II. Auxiliary Loss"}),e(i,null,{default:o(()=>[O,j,e(u,{src:t(n).CAN,class:"w-2/3"},null,8,["src"]),z]),_:1}),e(i,null,{default:o(()=>[A,e(u,{src:t(n).MSCM,class:"w-5/6"},null,8,["src"]),H]),_:1}),e(i,null,{default:o(()=>[F,X]),_:1})]),s("section",null,[e(c,{text:"III. Experiment"}),e(i,{class:"text-2xl"},{default:o(()=>[Y,s("div",q,[s("div",null,[l(" Epoch "),s("img",{src:t(n).epoch,class:"w-full"},null,8,Z)]),s("div",null,[l(" Training loss "),s("img",{src:t(n)["train-loss"],class:"w-full"},null,8,G)]),s("div",null,[l(" Validation loss "),s("img",{src:t(n)["val-loss"],class:"w-full"},null,8,K)])]),s("div",Q,[s("div",U,[l(" Validation accuracy: "),ss,s("img",{src:t(n)["val-acc"],class:"w-full"},null,8,es)]),ts])]),_:1}),e(i,null,{default:o(()=>[ls,ns,e(u,{src:t(T),class:"w-4/5"},null,8,["src"])]),_:1})]),e(c,{text:"Thank you!"})])])])}}};export{us as default};
