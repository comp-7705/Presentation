import{g as d,l as h,c as m,a as s,b as e,u as t,w as a,r as c,o as g,d as l}from"./index-351b7a93.js";import{_ as p}from"./Week1-a948707a.js";import{_ as b}from"./Week2-b24774d3.js";import{_ as f}from"./Week3-c8a048d0.js";import{_ as $}from"./Week4-cceb67fc.js";const v="/Presentation/assets/CAN-52d3dcfb.png",y="/Presentation/assets/epoch-93218eb7.svg",x="/Presentation/assets/mscm-d9094064.png",w="/Presentation/assets/train-loss-9f0a519f.svg",C="/Presentation/assets/val-acc-1c2bb9aa.svg",V="/Presentation/assets/val-loss-1158b1fb.svg",L="/Presentation/assets/phase3-1a1ac70a.jpg",M={class:"w-screen h-screen"},P={class:"reveal"},S={class:"slides"},I=s("h2",null,"Object Counting",-1),J=s("ul",null,[s("li",null,[l(" Regression-based methods: To learn counting by regressing a "),s("span",{class:"red-bold"},"density map"),l(", and the predicted count equals the integration of the density map. ")]),s("li",null," Multi-scale counting model(MSCM) is designed based on regression-based method, used to predict the number of each symbol class. ")],-1),N=s("span",{class:"text-xl italic"}," Li, B., Yuan, Y., Liang, D., Liu, X., Ji, Z., Bai, J., ... & Bai, X. (2022, October). When counting meets HMER: counting-aware network for handwritten mathematical expression recognition. In European Conference on Computer Vision (pp. 197-214). Cham: Springer Nature Switzerland. ",-1),E=s("h2",null,"Multi-scale Counting Module(MSCM)",-1),T=s("ul",null,[s("li",null," Two parallel multi-scale branches ($3 \\times 3$, $5 \\times 5$) are used to generate counting maps. Channel attention is adopted to enhance the feature extraction. "),s("li",null," In counting map, each map $\\mathbf{M_i}$ is actually a pseudo density map, where $\\mathbf{M_i} \\in \\mathbb{R}^{H \\times W}$. We can obtain counting vector $V$ by sum-pooling the counting map, where $V \\in \\mathbb{R}^{1\\times C}$, $C$ is the vocabulary size. "),s("li",null," Each element in $V$ is the predicted count of the i-th class symbol. ")],-1),B=s("h2",null,"Loss Function",-1),R=s("ul",null,[s("li",null," The updated loss function consists of two parts: $$ L=L_{cls}+L_{counting} $$ where $L=L_{cls}$ is a common-used cross entropy classification loss of the predicted probability with respect to its ground-truth. "),s("li",null," Denoting the counting ground truth of each symbol class as $\\hat{V}$: $$ L_{couting} = \\text{smooth}_{L1}(V, \\hat{V}) $$ "),s("li",null," For batch size $N$, Smooth L1 loss is defined: $$ \\ell(x, y) = L = \\{l_1, ..., l_N\\}^T $$ $$ l_n = \\begin{cases} 0.5 (x_n - y_n)^2, & \\text{if } |x_n - y_n| \\le 1.0 \\\\ |x_n - y_n| - 0.5, & \\text{otherwise } \\end{cases} $$ ")],-1),k=s("h2",null,"Experiment",-1),A={class:"grid grid-cols-3"},j=["src"],z=["src"],H=["src"],O={class:"grid grid-cols-5"},W={class:"col-span-3"},F=s("span",{class:"red-bold"},"0.597",-1),D=["src"],X=s("div",{class:"col-span-2"},[s("p",null,"Problems:"),s("ul",null,[s("li",null,"A sharp increse in validation loss."),s("li",null," Validation accuracy is a bit less than experiments done in the last week (0.60). ")])],-1),Y=s("h2",null,"Next Schedule",-1),q=s("ul",null,[s("li",null,"Finalize our model and deploy it."),s("li",null,"Write final report."),s("li",null,"Prepare final presentation.")],-1),ns={__name:"July13",setup(Z){const _=Object.values(Object.assign({"../assets/images/July13/CAN.png":v,"../assets/images/July13/epoch.svg":y,"../assets/images/July13/mscm.png":x,"../assets/images/July13/train-loss.svg":w,"../assets/images/July13/val-acc.svg":C,"../assets/images/July13/val-loss.svg":V})),n=d(_);return h(),(G,K)=>{const u=c("Cover"),i=c("HSection"),r=c("Image"),o=c("VSection");return g(),m("div",M,[s("div",P,[s("div",S,[e(u,{date:"July 13"}),s("section",null,[e(i,{text:"I. Recap"}),e(t(p)),e(t(b)),e(t(f)),e(t($))]),s("section",null,[e(i,{text:"II. Auxiliary Loss"}),e(o,null,{default:a(()=>[I,J,e(r,{src:t(n).CAN,class:"w-2/3"},null,8,["src"]),N]),_:1}),e(o,null,{default:a(()=>[E,e(r,{src:t(n).MSCM,class:"w-5/6"},null,8,["src"]),T]),_:1}),e(o,null,{default:a(()=>[B,R]),_:1})]),s("section",null,[e(i,{text:"III. Experiment"}),e(o,null,{default:a(()=>[k,s("div",A,[s("div",null,[l(" Epoch "),s("img",{src:t(n).epoch,class:"w-full"},null,8,j)]),s("div",null,[l(" Training loss "),s("img",{src:t(n)["train-loss"],class:"w-full"},null,8,z)]),s("div",null,[l(" Validation loss "),s("img",{src:t(n)["val-loss"],class:"w-full"},null,8,H)])]),s("div",O,[s("div",W,[l(" Validation accuracy: "),F,s("img",{src:t(n)["val-acc"],class:"w-full"},null,8,D)]),X])]),_:1}),e(o,null,{default:a(()=>[Y,q,e(r,{src:t(L),class:"w-4/5"},null,8,["src"])]),_:1})]),e(i,{text:"Thank you!"})])])])}}};export{ns as default};
